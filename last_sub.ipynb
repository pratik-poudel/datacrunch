{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratik-poudel/datacrunch/blob/main/last_sub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFemLGf_JiIK",
        "outputId": "04c8f6e8-8f8d-4182-f06e-a524471792c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.7.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.5.7)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (4.7.2)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.3.23)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (1.5.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.5.1)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from stevedore>=2.0.1->cliff->optuna) (3.7.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "import gc\n",
        "# pd.options.display.float_format| = \"{:.2f}\".format\n",
        "pd.options.display.max_columns = 500\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report , mean_squared_error, make_scorer\n",
        "import requests\n",
        "from scipy import stats\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.linear_model import SGDRegressor, ElasticNet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knz7f6FKI1EO"
      },
      "source": [
        "train_datalink_X = 'https://tournament.datacrunch.com/data/X_train.csv'  \n",
        "train_datalink_y = 'https://tournament.datacrunch.com/data/y_train.csv'\n",
        "hackathon_data_link = 'https://tournament.datacrunch.com/data/X_test.csv'\n",
        "train = pd.read_csv(train_datalink_X)\n",
        "target = pd.read_csv(train_datalink_y)\n",
        "test = pd.read_csv(hackathon_data_link)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCYLyH9BI4na"
      },
      "source": [
        "features = [f for f in train.columns if 'feature' in f]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lrcnuDoI6bC"
      },
      "source": [
        "def additional_features(df):\n",
        "    df['feature_17+feature_23+feature_8*feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_8'] * df['feature_21']\n",
        "    df['feature_23+feature_4+feature_8+feature_21'] = df['feature_23'] + df['feature_4'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_8*feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_8'] * df['feature_21']\n",
        "    df['feature_23+feature_11+feature_8+feature_21'] = df['feature_23'] + df['feature_11'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_17+feature_18+feature_23+feature_21'] = df['feature_17'] + df['feature_18'] + df['feature_23'] + df['feature_21']\n",
        "    df['feature_23+feature_12+feature_8+feature_21'] = df['feature_23'] + df['feature_12'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_17+feature_19+feature_23+feature_21'] = df['feature_17'] + df['feature_19'] + df['feature_23'] + df['feature_21']\n",
        "    df['feature_23+feature_5+feature_8+feature_21'] = df['feature_23'] + df['feature_5'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_23+feature_3+feature_8+feature_21'] = df['feature_23'] + df['feature_3'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_18+feature_19+feature_23+feature_21'] = df['feature_18'] + df['feature_19'] + df['feature_23'] + df['feature_21']\n",
        "    df['feature_23+feature_9+feature_8+feature_21'] = df['feature_23'] + df['feature_9'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_19+feature_23+feature_8*feature_21'] = df['feature_19'] + df['feature_23'] + df['feature_8'] * df['feature_21']\n",
        "    df['feature_17+feature_23+feature_16*feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_16'] * df['feature_21']\n",
        "    df['feature_17+feature_23+feature_8+feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_16*feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_16'] * df['feature_21']\n",
        "    df['feature_17+feature_23+feature_3*feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_3'] * df['feature_21']\n",
        "    df['feature_17+feature_23+feature_3+feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_3'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_8+feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_3*feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_3'] * df['feature_21']\n",
        "    df['feature_18+feature_23+feature_3+feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_3'] + df['feature_21']\n",
        "    df['feature_23+feature_8+feature_6+feature_21'] = df['feature_23'] + df['feature_8'] + df['feature_6'] + df['feature_21']\n",
        "    df['feature_17+feature_23+feature_16+feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_16'] + df['feature_21']\n",
        "    df['feature_23+feature_3+feature_8*feature_21'] = df['feature_23'] + df['feature_3'] + df['feature_8'] * df['feature_21']\n",
        "    df['feature_23+feature_8+feature_21+feature_13'] = df['feature_23'] + df['feature_8'] + df['feature_21'] + df['feature_13']\n",
        "    df['feature_17+feature_23+feature_11*feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_11'] * df['feature_21']\n",
        "    df['feature_23+feature_8+feature_6*feature_21'] = df['feature_23'] + df['feature_8'] + df['feature_6'] * df['feature_21']\n",
        "    df['feature_18+feature_23+feature_16+feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_16'] + df['feature_21']\n",
        "    df['feature_19+feature_23+feature_8+feature_21'] = df['feature_19'] + df['feature_23'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_23+feature_8+feature_21*feature_13'] = df['feature_23'] + df['feature_8'] + df['feature_21'] * df['feature_13']\n",
        "    df['feature_17+feature_8+feature_6+feature_21'] = df['feature_17'] + df['feature_8'] + df['feature_6'] + df['feature_21']\n",
        "    df['feature_17+feature_23+feature_11+feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_11'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_11*feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_11'] * df['feature_21']\n",
        "    df['feature_23+feature_8+feature_2*feature_21'] = df['feature_23'] + df['feature_8'] + df['feature_2'] * df['feature_21']\n",
        "    df['feature_23+feature_8+feature_2+feature_21'] = df['feature_23'] + df['feature_8'] + df['feature_2'] + df['feature_21']\n",
        "    df['feature_18+feature_8+feature_6+feature_21'] = df['feature_18'] + df['feature_8'] + df['feature_6'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_11+feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_11'] + df['feature_21']\n",
        "    df['feature_17+feature_23+feature_4*feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_4'] * df['feature_21']\n",
        "    df['feature_23+feature_11+feature_8*feature_21'] = df['feature_23'] + df['feature_11'] + df['feature_8'] * df['feature_21']\n",
        "    df['feature_17+feature_5+feature_8+feature_21'] = df['feature_17'] + df['feature_5'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_23+feature_22+feature_8+feature_21'] = df['feature_23'] + df['feature_22'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_17+feature_23+feature_4+feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_4'] + df['feature_21']\n",
        "    df['feature_18+feature_23+feature_4*feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_4'] * df['feature_21']\n",
        "    df['feature_19+feature_23+feature_3+feature_21'] = df['feature_19'] + df['feature_23'] + df['feature_3'] + df['feature_21']\n",
        "    df['feature_17+feature_19+feature_23*feature_21'] = df['feature_17'] + df['feature_19'] + df['feature_23'] * df['feature_21']\n",
        "    df['feature_18+feature_5+feature_8+feature_21'] = df['feature_18'] + df['feature_5'] + df['feature_8'] + df['feature_21']\n",
        "    df['feature_19+feature_23+feature_16*feature_21'] = df['feature_19'] + df['feature_23'] + df['feature_16'] * df['feature_21']\n",
        "    df['feature_18+feature_19+feature_23*feature_21'] = df['feature_18'] + df['feature_19'] + df['feature_23'] * df['feature_21']\n",
        "    df['feature_17+feature_23+feature_2*feature_21'] = df['feature_17'] + df['feature_23'] + df['feature_2'] * df['feature_21']\n",
        "    df['feature_23+feature_4+feature_8*feature_21'] = df['feature_23'] + df['feature_4'] + df['feature_8'] * df['feature_21']\n",
        "    df['feature_18+feature_23+feature_4+feature_21'] = df['feature_18'] + df['feature_23'] + df['feature_4'] + df['feature_21']\n",
        "    df['feature_23+feature_8+feature_10+feature_21'] = df['feature_23'] + df['feature_8'] + df['feature_10'] + df['feature_21']\n",
        "    df['feature_19+feature_23+feature_16+feature_21'] = df['feature_19'] + df['feature_23'] + df['feature_16'] + df['feature_21']\n",
        "    df['feature_19+feature_8+feature_6+feature_21'] = df['feature_19'] + df['feature_8'] + df['feature_6'] + df['feature_21']\n",
        "    df['feature_17+feature_18+feature_23*feature_21'] = df['feature_17'] + df['feature_18'] + df['feature_23'] * df['feature_21']\n",
        "    df['feature_23+feature_8+feature_10*feature_21'] = df['feature_23'] + df['feature_8'] + df['feature_10'] * df['feature_21']\n",
        "    return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmIqRxB8JDIq"
      },
      "source": [
        "unique_feature_set = {\n",
        "    'feature_10',\n",
        " 'feature_11',\n",
        " 'feature_12',\n",
        " 'feature_13',\n",
        " 'feature_16',\n",
        " 'feature_17',\n",
        " 'feature_18',\n",
        " 'feature_19',\n",
        " 'feature_2',\n",
        " 'feature_21',\n",
        " 'feature_22',\n",
        " 'feature_23',\n",
        " 'feature_3',\n",
        " 'feature_4',\n",
        " 'feature_5',\n",
        " 'feature_6',\n",
        " 'feature_8',\n",
        " 'feature_9'}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MN6j7RMJH9w"
      },
      "source": [
        "train = additional_features(train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6oMUS6w9Ry"
      },
      "source": [
        "test = additional_features(test)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulH_BPD3JL1x"
      },
      "source": [
        "features = [f for f in train.columns if 'feature' in f]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsf7JTmaJNNQ"
      },
      "source": [
        "def scorer(y_test, y_pred):\n",
        "    score = (stats.spearmanr(y_test, y_pred))[0]\n",
        "    # print('Score as calculated for the leader board (っಠ‿ಠ)っ {}'.format(score))\n",
        "    return score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "605fEiSEJRsa",
        "outputId": "f2b3ebe7-af41-4b8f-8cd6-9586be081f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = {'alpha': 0.0364014482430476,\n",
        " 'fit_intercept': True,\n",
        " 'l1_ratio': 0.30198788820905625,\n",
        " 'max_iter': 7085,\n",
        " 'normalize': False,\n",
        " 'random_state': 4928,\n",
        " 'selection': 'random',\n",
        " 'tol': 0.00814644265439289}\n",
        "from sklearn.linear_model import MultiTaskLasso, MultiTaskElasticNet\n",
        "X_train, X_test, y_train, y_test = train_test_split(train[features], target, test_size=0.25, shuffle=False)\n",
        "model = MultiTaskElasticNet(**params)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "print(scorer(y_test['target_r'], preds[:, 0]))\n",
        "print(scorer(y_test['target_g'], preds[:, 1]))\n",
        "print(scorer(y_test['target_b'], preds[:, 2]))\n",
        "print(\"MEAN SCORE :\", (scorer(y_test['target_r'], preds[:, 0]) \n",
        "+ scorer(y_test['target_g'], preds[:, 1]) \n",
        "+ scorer(y_test['target_b'], preds[:, 2])) / 3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3658408997272413\n",
            "0.5328872176456995\n",
            "0.6759614608152857\n",
            "MEAN SCORE : 0.5248965260627422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_h--zkgJU6H",
        "outputId": "8e8dde61-e9e3-45a4-839d-1d390767bab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "import optuna\n",
        "N_TRIALS = 300\n",
        "X_train, X_test, y_train, y_test = train_test_split(train[features], target, test_size=0.25, shuffle=False)\n",
        "\n",
        "def objective(trial):    \n",
        "    params = {\n",
        "            'alpha': trial.suggest_uniform('alpha', 0.001, 1),\n",
        "            'l1_ratio': trial.suggest_uniform('l1_ratio', 0.1, 1),\n",
        "            'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
        "            'normalize': trial.suggest_categorical('normalize', [True, False]),\n",
        "            'max_iter': trial.suggest_int('max_iter', 1000, 10000),\n",
        "            'tol': trial.suggest_loguniform('tol',1e-7, 1e-2),\n",
        "            'random_state': trial.suggest_int('random_state', 60, 5000),\n",
        "            'selection': trial.suggest_categorical('selection', ['cyclic', 'random']),\n",
        "\n",
        "            }\n",
        "\n",
        "    model = ElasticNet(**params)\n",
        "    wrapper = RegressorChain(model, [1, 2, 0])\n",
        "    wrapper.fit(X_train, y_train)\n",
        "    preds = wrapper.predict(X_test)\n",
        "    score = (scorer(y_test['target_r'], preds[:, 0]) +\n",
        "             scorer(y_test['target_g'], preds[:, 1]) +\n",
        "             scorer(y_test['target_b'], preds[:, 2])) /3\n",
        "    from google.colab import output\n",
        "    output.clear()\n",
        "    return score\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=N_TRIALS)\n",
        "\n",
        "display(study.best_params)\n",
        "display(study.best_trial.value)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m[W 2021-03-14 05:48:29,260]\u001b[0m Trial 299 failed, because the objective function returned nan.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'alpha': 0.04572179067561144,\n",
              " 'fit_intercept': True,\n",
              " 'l1_ratio': 0.3913114457420369,\n",
              " 'max_iter': 7735,\n",
              " 'normalize': False,\n",
              " 'random_state': 4412,\n",
              " 'selection': 'cyclic',\n",
              " 'tol': 2.1786679215766246e-05}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.5219300977933191"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArCpVecfJnKi",
        "outputId": "ab7ed3be-777e-45d9-8435-aec4438bff56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train[features], target, test_size=0.25, shuffle=False)\n",
        "params = {\n",
        "'alpha': 0.04572179067561144,\n",
        " 'fit_intercept': True,\n",
        " 'l1_ratio': 0.3913114457420369,\n",
        " 'max_iter': 7735,\n",
        " 'normalize': False,\n",
        " 'random_state': 4412,\n",
        " 'selection': 'cyclic',\n",
        " 'tol': 2.1786679215766246e-05\n",
        " \n",
        " }\n",
        "model = ElasticNet(**params)\n",
        "wrapper = RegressorChain(model, [1, 2, 0])\n",
        "wrapper.fit(X_train, y_train)\n",
        "preds = wrapper.predict(X_test)\n",
        "print((scorer(y_test['target_r'], preds[:, 0]) + scorer(y_test['target_g'], preds[:, 1]) + scorer(y_test['target_b'], preds[:, 2]))/ 3)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5219300977933191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byf92I-3R8_m"
      },
      "source": [
        "el_preds = pd.DataFrame(wrapper.predict(train[features]), columns=['el_r', 'el_g', 'el_b'])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTQngdTHzbty"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train[features_r], target.target_r, test_size=0.25, shuffle=False, random_state=2021)\n",
        "\n",
        "def scorer(y_test, y_pred):\n",
        "    score = (stats.spearmanr(y_test, y_pred))[0]\n",
        "    print('Score as calculated for the leader board (っಠ‿ಠ)っ {}'.format(score))\n",
        "    return score\n",
        "\n",
        "N_TRIALS = 500\n",
        "def objective(trial):    \n",
        "    params = {\n",
        "            'boosting_type': 'gbdt',\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'num_leaves': trial.suggest_int('num_leaves', 4, 32),\n",
        "            'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
        "            'learning_rate' : trial.suggest_uniform('learning_rate', 0.0001, 0.99),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
        "            'min_split_gain' : trial.suggest_uniform('min_split_gain', 0, 1),\n",
        "            'min_child_weight': trial.suggest_uniform('min_child_weight', 1e-3, 1),\n",
        "            'min_child_samples': trial.suggest_int('min_child_samples',20, 500),\n",
        "            'subsample' : trial.suggest_uniform('subsample', 0.5, 1),\n",
        "            'subsample_freq': trial.suggest_int('subsample_freq', 0, 1),\n",
        "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
        "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
        "\n",
        "            }\n",
        "\n",
        "    model = lgb.LGBMRegressor(**params, random_state=2021)\n",
        "    # wrapper = RegressorChain(model, [0, 1, 2], random_state=2021)\n",
        "    # wrapper.fit(X_train, y_train)\n",
        "    # preds = wrapper.predict(X_test)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=100)\n",
        "    preds = model.predict(X_test, model.best_iteration_)\n",
        "    \n",
        "    \n",
        "    score = scorer(y_test, preds)\n",
        "    \n",
        "    from google.colab import output\n",
        "    output.clear()\n",
        "    return score\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar= True)\n",
        "display(study.best_params)\n",
        "display(study.best_trial.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amak0TgbzbrA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FQYJCF8zboN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1xckeyAUKCg"
      },
      "source": [
        "features_r = ['feature_17+feature_23+feature_8*feature_21',\n",
        " 'feature_18+feature_23+feature_8*feature_21',\n",
        " 'feature_17+feature_23+feature_8+feature_21',\n",
        " 'feature_29',\n",
        " 'feature_19+feature_23+feature_8*feature_21',\n",
        " 'feature_18+feature_23+feature_8+feature_21',\n",
        " 'feature_10',\n",
        " 'feature_6']\n",
        "\n",
        "features_g = ['feature_23+feature_11+feature_8+feature_21',\n",
        " 'feature_23+feature_4+feature_8+feature_21',\n",
        " 'feature_17+feature_23+feature_8*feature_21',\n",
        " 'feature_23+feature_3+feature_8+feature_21',\n",
        " 'feature_17+feature_23+feature_16*feature_21',\n",
        " 'feature_28',\n",
        " 'feature_29',\n",
        " 'feature_25',\n",
        " 'feature_18+feature_23+feature_8*feature_21',\n",
        " 'feature_18+feature_23+feature_16+feature_21',\n",
        " 'feature_26',\n",
        " 'feature_17+feature_23+feature_3*feature_21',\n",
        " 'feature_17+feature_18+feature_23*feature_21',\n",
        " 'feature_23+feature_8+feature_10*feature_21',\n",
        " 'feature_4',\n",
        " 'feature_10',\n",
        " 'feature_19+feature_23+feature_16*feature_21',\n",
        " 'feature_5',\n",
        " 'feature_8']\n",
        "\n",
        "features_b = ['feature_17+feature_23+feature_11*feature_21',\n",
        " 'feature_17+feature_23+feature_4*feature_21',\n",
        " 'feature_18+feature_23+feature_4*feature_21',\n",
        " 'feature_18+feature_23+feature_16*feature_21',\n",
        " 'feature_18+feature_23+feature_3*feature_21',\n",
        " 'feature_28',\n",
        " 'feature_29',\n",
        " 'feature_25',\n",
        " 'feature_17',\n",
        " 'feature_23+feature_22+feature_8+feature_21',\n",
        " 'feature_10',\n",
        " 'feature_27']\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KigjGx_wlMIC"
      },
      "source": [
        "params_r = {'learning_rate': 0.1881762948600033,\n",
        " 'max_depth': 13,\n",
        " 'min_child_samples': 206,\n",
        " 'min_child_weight': 0.12317444550273453,\n",
        " 'min_split_gain': 0.6855476015190156,\n",
        " 'n_estimators': 3207,\n",
        " 'num_leaves': 28,\n",
        " 'reg_alpha': 0.000277215555022957,\n",
        " 'reg_lambda': 0.2112440706134894,\n",
        " 'subsample': 0.6575876839860837,\n",
        " 'subsample_freq': 1}\n",
        "\n",
        " # 0.3743431445071381\n",
        "\n",
        "params_g = {'num_leaves': 32, \n",
        " 'max_depth': 15,\n",
        " 'learning_rate': 0.0004900820824294886, \n",
        " 'n_estimators': 4982,\n",
        " 'min_split_gain': 0.9784852734402016, \n",
        " 'min_child_weight': 0.3654650150961478,\n",
        " 'min_child_samples': 453, \n",
        " 'subsample': 0.5435998642515718, \n",
        " 'subsample_freq': 1, \n",
        " 'reg_alpha': 0.0001358772967592931, \n",
        " 'reg_lambda': 1.3342132380913252e-05}\n",
        "# 0.541219083180964\n",
        " \n",
        "params_b = {'learning_rate': 0.09934904889912213,\n",
        " 'max_depth': 15,\n",
        " 'min_child_samples': 91,\n",
        " 'min_child_weight': 0.7401219517079427,\n",
        " 'min_split_gain': 0.46238343889524225,\n",
        " 'n_estimators': 1465,\n",
        " 'num_leaves': 5,\n",
        " 'reg_alpha': 0.007739393570563738,\n",
        " 'reg_lambda': 0.0003214724916951722,\n",
        " 'subsample': 0.8324856340437796,\n",
        " 'subsample_freq': 0}\n",
        "#0.6814260043800434"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czt8ri7WrqGo",
        "outputId": "5a1623b5-03aa-4813-a363-26e57f3cf2ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train[features_r], target.target_r, test_size=0.25, shuffle=False, random_state=2021)\n",
        "\n",
        "model_target_r = lgb.LGBMRegressor(**params_r, random_state=2021)\n",
        "\n",
        "model_target_r.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "preds_r = model_target_r.predict(X_test, model_target_r.best_iteration_)\n",
        "scorer(y_test, preds_r)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's l2: 0.111665\n",
            "Early stopping, best iteration is:\n",
            "[17]\tvalid_0's l2: 0.111664\n",
            "Score as calculated for the leader board (っಠ‿ಠ)っ 0.3743431445071381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3743431445071381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IShVmtE_xdDl",
        "outputId": "53e85386-cddd-464f-b283-e0d170463c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train[features_g], target.target_g, test_size=0.25, shuffle=False, random_state=2021)\n",
        "\n",
        "model_target_g = lgb.LGBMRegressor(**params_g, random_state=2021)\n",
        "\n",
        "model_target_g.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "preds_g = model_target_g.predict(X_test, model_target_g.best_iteration_)\n",
        "\n",
        "scorer(y_test, preds_g)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's l2: 0.121243\n",
            "[200]\tvalid_0's l2: 0.118455\n",
            "[300]\tvalid_0's l2: 0.115908\n",
            "[400]\tvalid_0's l2: 0.113583\n",
            "[500]\tvalid_0's l2: 0.111461\n",
            "[600]\tvalid_0's l2: 0.109521\n",
            "[700]\tvalid_0's l2: 0.107748\n",
            "[800]\tvalid_0's l2: 0.106123\n",
            "[900]\tvalid_0's l2: 0.10464\n",
            "[1000]\tvalid_0's l2: 0.103284\n",
            "[1100]\tvalid_0's l2: 0.102043\n",
            "[1200]\tvalid_0's l2: 0.100911\n",
            "[1300]\tvalid_0's l2: 0.0998731\n",
            "[1400]\tvalid_0's l2: 0.0989262\n",
            "[1500]\tvalid_0's l2: 0.0980575\n",
            "[1600]\tvalid_0's l2: 0.0972633\n",
            "[1700]\tvalid_0's l2: 0.0965356\n",
            "[1800]\tvalid_0's l2: 0.0958676\n",
            "[1900]\tvalid_0's l2: 0.0952581\n",
            "[2000]\tvalid_0's l2: 0.0947015\n",
            "[2100]\tvalid_0's l2: 0.0941887\n",
            "[2200]\tvalid_0's l2: 0.0937207\n",
            "[2300]\tvalid_0's l2: 0.0932925\n",
            "[2400]\tvalid_0's l2: 0.0929\n",
            "[2500]\tvalid_0's l2: 0.0925379\n",
            "[2600]\tvalid_0's l2: 0.0922065\n",
            "[2700]\tvalid_0's l2: 0.0919032\n",
            "[2800]\tvalid_0's l2: 0.0916256\n",
            "[2900]\tvalid_0's l2: 0.0913684\n",
            "[3000]\tvalid_0's l2: 0.0911345\n",
            "[3100]\tvalid_0's l2: 0.0909182\n",
            "[3200]\tvalid_0's l2: 0.0907191\n",
            "[3300]\tvalid_0's l2: 0.0905369\n",
            "[3400]\tvalid_0's l2: 0.0903678\n",
            "[3500]\tvalid_0's l2: 0.0902119\n",
            "[3600]\tvalid_0's l2: 0.0900699\n",
            "[3700]\tvalid_0's l2: 0.0899386\n",
            "[3800]\tvalid_0's l2: 0.0898182\n",
            "[3900]\tvalid_0's l2: 0.089705\n",
            "[4000]\tvalid_0's l2: 0.0896043\n",
            "[4100]\tvalid_0's l2: 0.08951\n",
            "[4200]\tvalid_0's l2: 0.089421\n",
            "[4300]\tvalid_0's l2: 0.0893395\n",
            "[4400]\tvalid_0's l2: 0.0892634\n",
            "[4500]\tvalid_0's l2: 0.0891932\n",
            "[4600]\tvalid_0's l2: 0.0891292\n",
            "[4700]\tvalid_0's l2: 0.0890686\n",
            "[4800]\tvalid_0's l2: 0.0890135\n",
            "[4900]\tvalid_0's l2: 0.0889634\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[4982]\tvalid_0's l2: 0.0889238\n",
            "Score as calculated for the leader board (っಠ‿ಠ)っ 0.541219083180964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.541219083180964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrl3KN5fxcUV",
        "outputId": "e6716e02-550c-479c-9598-235d071d76a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train[features_b], target.target_b, test_size=0.25, shuffle=False, random_state=2021)\n",
        "\n",
        "model_target_b = lgb.LGBMRegressor(**params_b, random_state=2021)\n",
        "\n",
        "model_target_b.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=100)\n",
        "\n",
        "preds_b = model_target_b.predict(X_test, model_target_b.best_iteration_)\n",
        "\n",
        "scorer(y_test, preds_b)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\tvalid_0's l2: 0.0674594\n",
            "Early stopping, best iteration is:\n",
            "[64]\tvalid_0's l2: 0.0674502\n",
            "Score as calculated for the leader board (っಠ‿ಠ)っ 0.6814260043800434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6814260043800434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BIN-vn5vpRn"
      },
      "source": [
        "prediction = pd.DataFrame()\n",
        "prediction['target_r'] = model_target_r.predict(test[features_r], num_iteration=model_target_r.best_iteration_)\n",
        "prediction['target_g'] = model_target_g.predict(test[features_g], num_iteration=model_target_g.best_iteration_)\n",
        "prediction['target_b'] = model_target_b.predict(test[features_b], num_iteration=model_target_b.best_iteration_)"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oAhZ-IstOMw",
        "outputId": "3ba9b9d7-89a7-417d-cfdf-5c2ec971a6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "prediction"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_r</th>\n",
              "      <th>target_g</th>\n",
              "      <th>target_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.409018</td>\n",
              "      <td>0.471319</td>\n",
              "      <td>0.361749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.579756</td>\n",
              "      <td>0.613757</td>\n",
              "      <td>0.655615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.422631</td>\n",
              "      <td>0.373635</td>\n",
              "      <td>0.264312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.556723</td>\n",
              "      <td>0.550042</td>\n",
              "      <td>0.607956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.433282</td>\n",
              "      <td>0.464283</td>\n",
              "      <td>0.392723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48532</th>\n",
              "      <td>0.671831</td>\n",
              "      <td>0.714529</td>\n",
              "      <td>0.729245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48533</th>\n",
              "      <td>0.727312</td>\n",
              "      <td>0.817538</td>\n",
              "      <td>0.890776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48534</th>\n",
              "      <td>0.686496</td>\n",
              "      <td>0.731974</td>\n",
              "      <td>0.793941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48535</th>\n",
              "      <td>0.727312</td>\n",
              "      <td>0.817538</td>\n",
              "      <td>0.890776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48536</th>\n",
              "      <td>0.293899</td>\n",
              "      <td>0.190026</td>\n",
              "      <td>0.087554</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48537 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       target_r  target_g  target_b\n",
              "0      0.409018  0.471319  0.361749\n",
              "1      0.579756  0.613757  0.655615\n",
              "2      0.422631  0.373635  0.264312\n",
              "3      0.556723  0.550042  0.607956\n",
              "4      0.433282  0.464283  0.392723\n",
              "...         ...       ...       ...\n",
              "48532  0.671831  0.714529  0.729245\n",
              "48533  0.727312  0.817538  0.890776\n",
              "48534  0.686496  0.731974  0.793941\n",
              "48535  0.727312  0.817538  0.890776\n",
              "48536  0.293899  0.190026  0.087554\n",
              "\n",
              "[48537 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWaJXJ1DxYH6",
        "outputId": "2a8d5f20-3eab-4dd8-ec97-0faa96ef42dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "API_KEY = \"0GIskIC9Rd1I8sMw6nStutbIbMx7AaZzAyNfuMOVAVWgJtNa1IVQHZAD3WPj\" # <- HERE\n",
        "\n",
        "r = requests.post(\"https://tournament.datacrunch.com/api/submission\",\n",
        "    files = {\n",
        "        \"file\": (\"x\", prediction.to_csv().encode('ascii'))\n",
        "    },\n",
        "    data = {\n",
        "        \"apiKey\": API_KEY\n",
        "    },\n",
        ")\n",
        "\n",
        "if r.status_code == 200:\n",
        "    print(\"Submission submitted :)\")\n",
        "elif r.status_code == 423:\n",
        "    print(\"ERR: Submissions are close\")\n",
        "    print(\"You can only submit during rounds eg: Friday 7pm GMT+1 to Sunday midnight GMT+1.\")\n",
        "    print(\"Or the server is currently crunching the submitted files, please wait some time before retrying.\")\n",
        "elif r.status_code == 422:\n",
        "    print(\"ERR: API Key is missing or empty\")\n",
        "    print(\"Did you forget to fill the API_KEY variable?\")\n",
        "elif r.status_code == 404:\n",
        "    print(\"ERR: Unknown API Key\")\n",
        "    print(\"You should check that the provided API key is valid and is the same as the one you've received by email.\")\n",
        "elif r.status_code == 400:\n",
        "    print(\"ERR: The file must not be empty\")\n",
        "    print(\"You have send a empty file.\")\n",
        "elif r.status_code == 401:\n",
        "    print(\"ERR: Your email hasn't been verified\")\n",
        "    print(\"Please verify your email or contact a cruncher.\")\n",
        "elif r.status_code == 429:\n",
        "    print(\"ERR: Too many submissions\")\n",
        "else:\n",
        "    print(\"ERR: Server returned: \" + str(r.status_code))\n",
        "    print(\"Ouch! It seems that we were not expecting this kind of result from the server, if the probleme persist, contact a cruncher.\")"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission submitted :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndXIblhA0r4j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}